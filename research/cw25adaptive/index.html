<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Adaptive Vision-Based Control for Flexible Robot with Unknown Environmental Constraints</title>

  <style>
    /* ===== Base Paper Layout ===== */

    body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont,
                   "Segoe UI", Roboto, Arial, sans-serif;
      color: #1f2328;
      background: #ffffff;
    }

    .paper-page {
      display: flex;
      justify-content: center;
      width: 100%;
    }

    .paper-container {
      width: 100%;
      max-width: 880px;
      padding: 3rem 1.5rem;
      line-height: 1.7;
    }

    .paper-title,
    .paper-authors,
    .paper-venue,
    .paper-links {
      text-align: center;
    }

    .paper-title {
      font-size: 2rem;
      margin-bottom: 0.6rem;
    }

    .paper-authors {
      font-size: 1.05rem;
      margin-bottom: 0.4rem;
    }

    .paper-venue {
      color: #6a737d;
      margin-bottom: 1.2rem;
    }

    /* ===== Paper Links (VGGT style) ===== */

    .paper-links a {
      display: inline-block;
      margin: 0 0.4rem;
      padding: 0.45rem 0.9rem;
      border: 1px solid #1f2328;
      border-radius: 6px;
      text-decoration: none;
      color: #1f2328;
      font-weight: 500;
      font-size: 0.95rem;
    }

    .paper-links a:hover {
      background: #f3f4f6;
    }

    /* ===== Hero / Teaser Image ===== */

    .paper-figure {
      margin: 2.5rem 0;
      text-align: center;
    }

    .paper-figure img {
      max-width: 100%;
      border-radius: 8px;
    }

    /* ===== Sections ===== */

    .paper-section h2 {
      margin-top: 3rem;
      padding-bottom: 0.4rem;
      border-bottom: 1px solid #e5e7eb;
    }

    .paper-abstract {
      max-width: 70ch;
      margin: 1rem auto 0;
      text-align: justify;
    }

    /* ===== Image Grid (Results / Qualitative) ===== */

    .paper-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 1.5rem;
      margin-top: 1.5rem;
      justify-items: center;
    }

    .paper-grid figure {
      margin: 0;
      text-align: center;
      width: 100%;
    }

    .paper-grid img {
      width: 100%;
      max-width: 100%;
      border-radius: 6px;
    }

    .paper-grid figcaption {
      margin-top: 0.5rem;
      font-size: 0.9rem;
      color: #555;
      line-height: 1.4;
    }

    /* ===== BibTeX ===== */

    .paper-bibtex {
      background: #f6f8fa;
      padding: 1rem;
      font-size: 0.9rem;
      overflow-x: auto;
      border-radius: 6px;
    }

    /* ===== Mobile ===== */

    @media (max-width: 768px) {
      .paper-container {
        padding: 2rem 1.2rem;
      }
    }
  </style>
</head>

<body>
  <main class="paper-page">
    <div class="paper-container">
      
<h1 class="paper-title">Adaptive Vision-Based Control for Flexible Robot with Unknown Environmental Constraints</h1>

<div class="paper-authors">
  Wei Chen, Haiwen Wu, Bohan Yang, Jinfei Hu, Yun-Hui Liu
</div>

<div class="paper-venue">
  <em>IEEE International Conference on Real-time Computing and Robotics (RCAR)</em>, 2025
</div>

<div class="paper-links">
  <a href="https://doi.org/10.1109/RCAR65431.2025.11139652" target="_blank">Paper</a>
  Â· <a href="https://doi.org/10.1109/RCAR65431.2025.11139652" target="_blank">DOI</a>
</div>

<figure class="paper-figure">
  <img src="/research/cw25adaptive/photo.png" alt="Adaptive Vision-Based Control for Flexible Robot with Unknown Environmental Constraints">
</figure>

<hr>

<div class="paper-section">
  <h2>Abstract</h2>
  <p class="paper-abstract">
    This paper presents an adaptive vision-based control framework for flexible robots
    operating under unknown environmental constraints. The proposed method integrates
    real-time visual sensing and adaptive control strategies to estimate environmental
    geometry and robot deformation online. By leveraging vision-based pose and shape
    estimation, the robot achieves robust task execution without prior knowledge of
    environmental constraints.
  </p>
</div>

<div class="paper-section">
  <h2>Method Overview</h2>
  <p>
    We propose a vision-based adaptive control framework that tightly couples real-time
    visual perception with online deformation and constraint estimation. The controller
    adapts robot motion in response to estimated environmental geometry without requiring
    prior models.
  </p>
</div>

<div class="paper-section">
  <h2>Results</h2>

  <div class="paper-grid">
    <img src="/research/cw25adaptive/images/simulation_1.png" alt="Three DoFs flexible robot simulation">

    <img src="/research/cw25adaptive/images/simulation_2.png" alt="Two DoFs flexible robot simulation">
  </div>

  <p style="margin-top: 1rem; font-size: 0.95rem; color: #555; line-height: 1.5;">
    Simulation results of flexible robot control.
    The first figure shows the three-DoFs flexible robot, and the second one shows the
    two-DoFs flexible robot.
    For each case, we compare the image trajectory and image error obtained by the
    proposed method and the classical model-based approach, demonstrating improved
    tracking accuracy and robustness under unknown environmental constraints.
  </p>
</div>

<div class="paper-section">
  <h2>Citation</h2>
  <pre class="paper-bibtex">
@INPROCEEDINGS{11139652,
  author    = {Chen, Wei and Wu, Haiwen and Yang, Bohan and Hu, Jinfei and Liu, Yun-Hui},
  title     = {Adaptive Vision-Based Control for Flexible Robot with Unknown Environmental Constraints},
  booktitle = {2025 IEEE International Conference on Real-time Computing and Robotics (RCAR)},
  pages     = {745--750},
  year      = {2025},
  doi       = {10.1109/RCAR65431.2025.11139652}
}
  </pre>
</div>


    </div>
  </main>
</body>
</html>
